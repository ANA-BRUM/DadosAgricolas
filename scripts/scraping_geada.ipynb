{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import pandas as pd\n",
    "import logging\n",
    "import calendar\n",
    "import unidecode\n",
    "import locale\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a localização para português\n",
    "locale.setlocale(locale.LC_TIME, 'pt_BR.UTF-8')\n",
    "\n",
    "# Configuração do logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%d/%m/%Y %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Diminuir o nível de log para o httpx e outros loggers de terceiros\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20/10/2024 17:13:14 - INFO - Extraindo dados para: Janeiro de 2017\n",
      "20/10/2024 17:13:14 - INFO - Extraindo dados para: Fevereiro de 2017\n",
      "20/10/2024 17:13:15 - INFO - Extraindo dados para: Marã§o de 2017\n",
      "20/10/2024 17:13:15 - INFO - Extraindo dados para: Abril de 2017\n",
      "20/10/2024 17:13:15 - INFO - Extraindo dados para: Maio de 2017\n",
      "20/10/2024 17:13:16 - INFO - Extraindo dados para: Junho de 2017\n",
      "20/10/2024 17:13:17 - INFO - Extraindo dados para: Julho de 2017\n",
      "20/10/2024 17:13:17 - INFO - Extraindo dados para: Agosto de 2017\n",
      "20/10/2024 17:13:18 - INFO - Extraindo dados para: Setembro de 2017\n",
      "20/10/2024 17:13:18 - INFO - Extraindo dados para: Outubro de 2017\n",
      "20/10/2024 17:13:19 - INFO - Extraindo dados para: Novembro de 2017\n",
      "20/10/2024 17:13:19 - INFO - Extraindo dados para: Dezembro de 2017\n",
      "20/10/2024 17:13:20 - INFO - Extraindo dados para: Janeiro de 2018\n",
      "20/10/2024 17:13:20 - INFO - Extraindo dados para: Fevereiro de 2018\n",
      "20/10/2024 17:13:21 - INFO - Extraindo dados para: Marã§o de 2018\n",
      "20/10/2024 17:13:21 - INFO - Extraindo dados para: Abril de 2018\n",
      "20/10/2024 17:13:21 - INFO - Extraindo dados para: Maio de 2018\n",
      "20/10/2024 17:13:22 - INFO - Extraindo dados para: Junho de 2018\n",
      "20/10/2024 17:13:23 - INFO - Extraindo dados para: Julho de 2018\n",
      "20/10/2024 17:13:23 - INFO - Extraindo dados para: Agosto de 2018\n",
      "20/10/2024 17:13:24 - INFO - Extraindo dados para: Setembro de 2018\n",
      "20/10/2024 17:13:24 - INFO - Extraindo dados para: Outubro de 2018\n",
      "20/10/2024 17:13:25 - INFO - Extraindo dados para: Novembro de 2018\n",
      "20/10/2024 17:13:25 - INFO - Extraindo dados para: Dezembro de 2018\n",
      "20/10/2024 17:13:26 - INFO - Extraindo dados para: Janeiro de 2019\n",
      "20/10/2024 17:13:26 - INFO - Extraindo dados para: Fevereiro de 2019\n",
      "20/10/2024 17:13:27 - INFO - Extraindo dados para: Marã§o de 2019\n",
      "20/10/2024 17:13:27 - INFO - Extraindo dados para: Abril de 2019\n",
      "20/10/2024 17:13:28 - INFO - Extraindo dados para: Maio de 2019\n",
      "20/10/2024 17:13:28 - INFO - Extraindo dados para: Junho de 2019\n",
      "20/10/2024 17:13:29 - INFO - Extraindo dados para: Julho de 2019\n",
      "20/10/2024 17:13:29 - INFO - Extraindo dados para: Agosto de 2019\n",
      "20/10/2024 17:13:30 - INFO - Extraindo dados para: Setembro de 2019\n",
      "20/10/2024 17:13:31 - INFO - Extraindo dados para: Outubro de 2019\n",
      "20/10/2024 17:13:31 - INFO - Extraindo dados para: Novembro de 2019\n",
      "20/10/2024 17:13:31 - INFO - Extraindo dados para: Dezembro de 2019\n",
      "20/10/2024 17:13:32 - INFO - Extraindo dados para: Janeiro de 2020\n",
      "20/10/2024 17:13:32 - INFO - Extraindo dados para: Fevereiro de 2020\n",
      "20/10/2024 17:13:33 - INFO - Extraindo dados para: Marã§o de 2020\n",
      "20/10/2024 17:13:33 - INFO - Extraindo dados para: Abril de 2020\n",
      "20/10/2024 17:13:34 - INFO - Extraindo dados para: Maio de 2020\n",
      "20/10/2024 17:13:34 - INFO - Extraindo dados para: Junho de 2020\n",
      "20/10/2024 17:13:35 - INFO - Extraindo dados para: Julho de 2020\n",
      "20/10/2024 17:13:36 - INFO - Extraindo dados para: Agosto de 2020\n",
      "20/10/2024 17:13:36 - INFO - Extraindo dados para: Setembro de 2020\n",
      "20/10/2024 17:13:37 - INFO - Extraindo dados para: Outubro de 2020\n",
      "20/10/2024 17:13:37 - INFO - Extraindo dados para: Novembro de 2020\n",
      "20/10/2024 17:13:38 - INFO - Extraindo dados para: Dezembro de 2020\n",
      "20/10/2024 17:13:38 - INFO - Extraindo dados para: Janeiro de 2021\n",
      "20/10/2024 17:13:38 - INFO - Extraindo dados para: Fevereiro de 2021\n",
      "20/10/2024 17:13:39 - INFO - Extraindo dados para: Marã§o de 2021\n",
      "20/10/2024 17:13:39 - INFO - Extraindo dados para: Abril de 2021\n",
      "20/10/2024 17:13:40 - INFO - Extraindo dados para: Maio de 2021\n",
      "20/10/2024 17:13:40 - INFO - Extraindo dados para: Junho de 2021\n",
      "20/10/2024 17:13:41 - INFO - Extraindo dados para: Julho de 2021\n",
      "20/10/2024 17:13:42 - INFO - Extraindo dados para: Agosto de 2021\n",
      "20/10/2024 17:13:42 - INFO - Extraindo dados para: Setembro de 2021\n",
      "20/10/2024 17:13:43 - INFO - Extraindo dados para: Outubro de 2021\n",
      "20/10/2024 17:13:43 - INFO - Extraindo dados para: Novembro de 2021\n",
      "20/10/2024 17:13:44 - INFO - Extraindo dados para: Dezembro de 2021\n",
      "20/10/2024 17:13:44 - INFO - Extraindo dados para: Janeiro de 2022\n",
      "20/10/2024 17:13:44 - INFO - Extraindo dados para: Fevereiro de 2022\n",
      "20/10/2024 17:13:45 - INFO - Extraindo dados para: Marã§o de 2022\n",
      "20/10/2024 17:13:45 - INFO - Extraindo dados para: Abril de 2022\n",
      "20/10/2024 17:13:46 - INFO - Extraindo dados para: Maio de 2022\n",
      "20/10/2024 17:13:46 - INFO - Extraindo dados para: Junho de 2022\n",
      "20/10/2024 17:13:47 - INFO - Extraindo dados para: Julho de 2022\n",
      "20/10/2024 17:13:48 - INFO - Extraindo dados para: Agosto de 2022\n",
      "20/10/2024 17:13:48 - INFO - Extraindo dados para: Setembro de 2022\n",
      "20/10/2024 17:13:49 - INFO - Extraindo dados para: Outubro de 2022\n",
      "20/10/2024 17:13:49 - INFO - Extraindo dados para: Novembro de 2022\n",
      "20/10/2024 17:13:49 - INFO - Extraindo dados para: Dezembro de 2022\n",
      "20/10/2024 17:13:50 - INFO - Extraindo dados para: Janeiro de 2023\n",
      "20/10/2024 17:13:50 - INFO - Extraindo dados para: Fevereiro de 2023\n",
      "20/10/2024 17:13:51 - INFO - Extraindo dados para: Marã§o de 2023\n",
      "20/10/2024 17:13:51 - INFO - Extraindo dados para: Abril de 2023\n",
      "20/10/2024 17:13:52 - INFO - Extraindo dados para: Maio de 2023\n",
      "20/10/2024 17:13:52 - INFO - Extraindo dados para: Junho de 2023\n",
      "20/10/2024 17:13:53 - INFO - Extraindo dados para: Julho de 2023\n",
      "20/10/2024 17:13:53 - INFO - Extraindo dados para: Agosto de 2023\n",
      "20/10/2024 17:13:54 - INFO - Extraindo dados para: Setembro de 2023\n",
      "20/10/2024 17:13:54 - INFO - Extraindo dados para: Outubro de 2023\n",
      "20/10/2024 17:13:55 - INFO - Extraindo dados para: Novembro de 2023\n",
      "20/10/2024 17:13:55 - INFO - Extraindo dados para: Dezembro de 2023\n",
      "20/10/2024 17:13:56 - INFO - Extraindo dados para: Janeiro de 2024\n",
      "20/10/2024 17:13:56 - INFO - Extraindo dados para: Fevereiro de 2024\n",
      "20/10/2024 17:13:57 - INFO - Extraindo dados para: Marã§o de 2024\n",
      "20/10/2024 17:13:57 - INFO - Extraindo dados para: Abril de 2024\n",
      "20/10/2024 17:13:57 - INFO - Extraindo dados para: Maio de 2024\n",
      "20/10/2024 17:13:58 - INFO - Extraindo dados para: Junho de 2024\n",
      "20/10/2024 17:13:58 - INFO - Extraindo dados para: Julho de 2024\n",
      "20/10/2024 17:13:59 - INFO - Extraindo dados para: Agosto de 2024\n",
      "20/10/2024 17:14:00 - INFO - Extraindo dados para: Setembro de 2024\n",
      "20/10/2024 17:14:00 - INFO - Dados extraídos e salvos com sucesso no arquivo 'C:\\Users\\ana.brum\\Área de Trabalho\\DadosMeteorologicos\\dados_geada.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Diminuir o nível de log para o httpx e outros loggers de terceiros\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "def fazer_requisicao(url: str, timeout: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Faz a requisição para a API e retorna os dados.\n",
    "    \n",
    "    Parâmetros:\n",
    "        url (str): URL da requisição.\n",
    "        timeout (int): Tempo máximo de espera para a resposta.\n",
    "\n",
    "    Retorna:\n",
    "        list: Dados da resposta em formato JSON ou uma lista vazia.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = httpx.get(url, timeout=timeout)\n",
    "        response.raise_for_status()  # Levanta exceção para códigos HTTP >= 400\n",
    "        return response.json()\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        logger.error(f\"Erro HTTP {e.response.status_code} ao fazer requisição para {url}\")\n",
    "        return []\n",
    "    except httpx.RequestError as e:\n",
    "        logger.error(f\"Erro na requisição: {e}\")\n",
    "        return []\n",
    "\n",
    "def formatar_data_brasileira(data_iso: str) -> str:\n",
    "    \"\"\"\n",
    "    Converte a data do formato ISO para o formato brasileiro.\n",
    "\n",
    "    Parâmetros:\n",
    "        data_iso (str): Data em formato ISO (YYYY-MM-DD).\n",
    "\n",
    "    Retorna:\n",
    "        str: Data no formato DD/MM/YYYY.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_formatada = datetime.strptime(data_iso, '%Y-%m-%d').strftime('%d/%m/%Y')\n",
    "        return data_formatada\n",
    "    except ValueError:\n",
    "        logger.error(f\"Erro ao formatar a data: {data_iso}\")\n",
    "        return \"Data inválida\"\n",
    "\n",
    "def formatar_temperatura(temperatura: str) -> str:\n",
    "    \"\"\"\n",
    "    Formata a temperatura, garantindo que seja exibida com uma casa decimal.\n",
    "\n",
    "    Parâmetros:\n",
    "        temperatura (str): Valor da temperatura.\n",
    "\n",
    "    Retorna:\n",
    "        str: Temperatura formatada com uma casa decimal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return f\"{float(temperatura):.1f}°C\"\n",
    "    except (TypeError, ValueError):\n",
    "        return \"N/A\"\n",
    "\n",
    "def calcular_intensidade(temp_min: str) -> str:\n",
    "    \"\"\"\n",
    "    Calcula a intensidade da geada com base na temperatura mínima.\n",
    "\n",
    "    Parâmetros:\n",
    "        temp_min (str): Temperatura mínima.\n",
    "\n",
    "    Retorna:\n",
    "        str: Intensidade da geada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp_min_float = float(temp_min)\n",
    "        if temp_min_float < 1:\n",
    "            return \"Forte\"\n",
    "        elif temp_min_float <= 3:\n",
    "            return \"Moderada\"\n",
    "        else:\n",
    "            return \"Fraca\"\n",
    "    except (TypeError, ValueError):\n",
    "        return \"N/A\"\n",
    "\n",
    "def buscar_id_por_nome(cidades: list, nome_cidade: str) -> int:\n",
    "    \"\"\"\n",
    "    Busca o ID do município pelo nome.\n",
    "\n",
    "    Parâmetros:\n",
    "        cidades (list): Lista de dicionários com os dados dos municípios.\n",
    "        nome_cidade (str): Nome do município a ser buscado.\n",
    "\n",
    "    Retorna:\n",
    "        int: ID do município ou -1 se não for encontrado.\n",
    "    \"\"\"\n",
    "    nome_cidade_normalizado = unidecode.unidecode(nome_cidade).lower()\n",
    "    for cidade in cidades:\n",
    "        nome_cidade_api_normalizado = unidecode.unidecode(cidade[\"nome\"]).lower()\n",
    "        if nome_cidade_api_normalizado == nome_cidade_normalizado:\n",
    "            return cidade[\"id\"]\n",
    "    return -1\n",
    "\n",
    "def extrair_dados_geada(folder_path: str = r\"C:\\Users\\ana.brum\\Área de Trabalho\\DadosMeteorologicos\"):\n",
    "    \"\"\"\n",
    "    Extrai os dados de geadas da API e salva em um arquivo Excel.\n",
    "    \n",
    "    Parâmetros:\n",
    "        folder_path (str): Caminho da pasta onde o arquivo Excel será salvo.\n",
    "    \"\"\"\n",
    "    cidades = fazer_requisicao(\"https://servicodados.ibge.gov.br/api/v1/localidades/municipios\")\n",
    "    if not cidades:\n",
    "        logger.error(\"Não foi possível obter a lista de municípios.\")\n",
    "        return\n",
    "\n",
    "    data_inicio = datetime(2017, 1, 1)\n",
    "    data_fim = datetime(2024, 9, 30)\n",
    "    dados_tratados = []\n",
    "\n",
    "    while data_inicio <= data_fim:\n",
    "        ano = data_inicio.year\n",
    "        mes = data_inicio.month\n",
    "        nome_mes = data_inicio.strftime('%B').capitalize()\n",
    "\n",
    "        logger.info(f\"Extraindo dados para: {nome_mes} de {ano}\")\n",
    "\n",
    "        primeiro_dia = data_inicio.strftime(\"%Y-%m-%d\")\n",
    "        ultimo_dia = (data_inicio + timedelta(days=calendar.monthrange(ano, mes)[1] - 1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        url = f\"https://apitempo.inmet.gov.br/geada/{primeiro_dia}/{ultimo_dia}/CONVENCIONAL\"\n",
    "        dados = fazer_requisicao(url)\n",
    "\n",
    "        # Tratamento dos dados\n",
    "        if dados:\n",
    "            for item in dados:\n",
    "                uf = item.get(\"UF\", \"N/A\")\n",
    "                nome_cidade = item.get(\"NOME\", \"N/A\").title()\n",
    "                data_ocorrencia = formatar_data_brasileira(item.get(\"DT_MEDICAO\"))\n",
    "                temp_min = item.get(\"TEMP_MIN\")\n",
    "                temperatura_formatada = formatar_temperatura(temp_min)\n",
    "                intensidade = calcular_intensidade(temp_min)\n",
    "                id_cidade = buscar_id_por_nome(cidades, nome_cidade)\n",
    "\n",
    "                # Adicionando os dados tratados à lista\n",
    "                dados_tratados.append([id_cidade, uf, nome_cidade, data_ocorrencia, temperatura_formatada, intensidade])\n",
    "\n",
    "        # Avançar para o próximo mês\n",
    "        data_inicio += timedelta(days=calendar.monthrange(ano, mes)[1])\n",
    "\n",
    "    # Criar DataFrame com os dados tratados\n",
    "    colunas = [\"Cod. IBGE\", \"Uf\", \"Município\", \"Dia de ocorrência\", \"Temperatura Mínima\", \"Intensidade\"]\n",
    "    df = pd.DataFrame(dados_tratados, columns=colunas)\n",
    "\n",
    "    # Certificando-se de que a pasta existe\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Caminho completo do arquivo Excel\n",
    "    excel_file = os.path.join(folder_path, \"dados_geada.xlsx\")\n",
    "    df.to_excel(excel_file, index=False)\n",
    "    logger.info(f\"Dados extraídos e salvos com sucesso no arquivo '{excel_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extrair_dados_geada()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
