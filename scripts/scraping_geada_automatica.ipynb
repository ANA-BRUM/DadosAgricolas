{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import pandas as pd\n",
    "import logging\n",
    "import calendar\n",
    "import unidecode\n",
    "import openpyxl\n",
    "import locale\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a localização para português\n",
    "locale.setlocale(locale.LC_TIME, 'pt_BR.UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração do logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%d/%m/%Y %H:%M:%S'\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Diminuir o nível de log para o httpx e outros loggers de terceiros\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17/02/2025 00:59:15 - INFO - Extraindo dados para: January de 2017\n",
      "17/02/2025 00:59:16 - INFO - Extraindo dados para: February de 2017\n",
      "17/02/2025 00:59:16 - INFO - Extraindo dados para: March de 2017\n",
      "17/02/2025 00:59:17 - INFO - Extraindo dados para: April de 2017\n",
      "17/02/2025 00:59:17 - INFO - Extraindo dados para: May de 2017\n",
      "17/02/2025 00:59:18 - INFO - Extraindo dados para: June de 2017\n",
      "17/02/2025 00:59:19 - INFO - Extraindo dados para: July de 2017\n",
      "17/02/2025 00:59:22 - INFO - Extraindo dados para: August de 2017\n",
      "17/02/2025 00:59:23 - INFO - Extraindo dados para: September de 2017\n",
      "17/02/2025 00:59:23 - INFO - Extraindo dados para: October de 2017\n",
      "17/02/2025 00:59:24 - INFO - Extraindo dados para: November de 2017\n",
      "17/02/2025 00:59:25 - INFO - Extraindo dados para: December de 2017\n",
      "17/02/2025 00:59:25 - INFO - Extraindo dados para: January de 2018\n",
      "17/02/2025 00:59:26 - INFO - Extraindo dados para: February de 2018\n",
      "17/02/2025 00:59:26 - INFO - Extraindo dados para: March de 2018\n",
      "17/02/2025 00:59:27 - INFO - Extraindo dados para: April de 2018\n",
      "17/02/2025 00:59:27 - INFO - Extraindo dados para: May de 2018\n",
      "17/02/2025 00:59:28 - INFO - Extraindo dados para: June de 2018\n",
      "17/02/2025 00:59:31 - INFO - Extraindo dados para: July de 2018\n",
      "17/02/2025 00:59:33 - INFO - Extraindo dados para: August de 2018\n",
      "17/02/2025 00:59:36 - INFO - Extraindo dados para: September de 2018\n",
      "17/02/2025 00:59:36 - INFO - Extraindo dados para: October de 2018\n",
      "17/02/2025 00:59:37 - INFO - Extraindo dados para: November de 2018\n",
      "17/02/2025 00:59:37 - INFO - Extraindo dados para: December de 2018\n",
      "17/02/2025 00:59:38 - INFO - Extraindo dados para: January de 2019\n",
      "17/02/2025 00:59:38 - INFO - Extraindo dados para: February de 2019\n",
      "17/02/2025 00:59:39 - INFO - Extraindo dados para: March de 2019\n",
      "17/02/2025 00:59:39 - INFO - Extraindo dados para: April de 2019\n",
      "17/02/2025 00:59:40 - INFO - Extraindo dados para: May de 2019\n",
      "17/02/2025 00:59:41 - INFO - Extraindo dados para: June de 2019\n",
      "17/02/2025 00:59:42 - INFO - Extraindo dados para: July de 2019\n",
      "17/02/2025 00:59:46 - INFO - Extraindo dados para: August de 2019\n",
      "17/02/2025 00:59:49 - INFO - Extraindo dados para: September de 2019\n",
      "17/02/2025 00:59:50 - INFO - Extraindo dados para: October de 2019\n",
      "17/02/2025 00:59:51 - INFO - Extraindo dados para: November de 2019\n",
      "17/02/2025 00:59:51 - INFO - Extraindo dados para: December de 2019\n",
      "17/02/2025 00:59:52 - INFO - Extraindo dados para: January de 2020\n",
      "17/02/2025 00:59:52 - INFO - Extraindo dados para: February de 2020\n",
      "17/02/2025 00:59:53 - INFO - Extraindo dados para: March de 2020\n",
      "17/02/2025 00:59:54 - INFO - Extraindo dados para: April de 2020\n",
      "17/02/2025 00:59:54 - INFO - Extraindo dados para: May de 2020\n",
      "17/02/2025 00:59:56 - INFO - Extraindo dados para: June de 2020\n",
      "17/02/2025 00:59:57 - INFO - Extraindo dados para: July de 2020\n",
      "17/02/2025 01:00:01 - INFO - Extraindo dados para: August de 2020\n",
      "17/02/2025 01:00:03 - INFO - Extraindo dados para: September de 2020\n",
      "17/02/2025 01:00:04 - INFO - Extraindo dados para: October de 2020\n",
      "17/02/2025 01:00:04 - INFO - Extraindo dados para: November de 2020\n",
      "17/02/2025 01:00:05 - INFO - Extraindo dados para: December de 2020\n",
      "17/02/2025 01:00:05 - INFO - Extraindo dados para: January de 2021\n",
      "17/02/2025 01:00:06 - INFO - Extraindo dados para: February de 2021\n",
      "17/02/2025 01:00:07 - INFO - Extraindo dados para: March de 2021\n",
      "17/02/2025 01:00:07 - INFO - Extraindo dados para: April de 2021\n",
      "17/02/2025 01:00:08 - INFO - Extraindo dados para: May de 2021\n",
      "17/02/2025 01:00:09 - INFO - Extraindo dados para: June de 2021\n",
      "17/02/2025 01:00:11 - INFO - Extraindo dados para: July de 2021\n",
      "17/02/2025 01:00:16 - INFO - Extraindo dados para: August de 2021\n",
      "17/02/2025 01:00:18 - INFO - Extraindo dados para: September de 2021\n",
      "17/02/2025 01:00:18 - INFO - Extraindo dados para: October de 2021\n",
      "17/02/2025 01:00:19 - INFO - Extraindo dados para: November de 2021\n",
      "17/02/2025 01:00:19 - INFO - Extraindo dados para: December de 2021\n",
      "17/02/2025 01:00:20 - INFO - Extraindo dados para: January de 2022\n",
      "17/02/2025 01:00:20 - INFO - Extraindo dados para: February de 2022\n",
      "17/02/2025 01:00:21 - INFO - Extraindo dados para: March de 2022\n",
      "17/02/2025 01:00:21 - INFO - Extraindo dados para: April de 2022\n",
      "17/02/2025 01:00:22 - INFO - Extraindo dados para: May de 2022\n",
      "17/02/2025 01:00:23 - INFO - Extraindo dados para: June de 2022\n",
      "17/02/2025 01:00:26 - INFO - Extraindo dados para: July de 2022\n",
      "17/02/2025 01:00:27 - INFO - Extraindo dados para: August de 2022\n",
      "17/02/2025 01:00:29 - INFO - Extraindo dados para: September de 2022\n",
      "17/02/2025 01:00:30 - INFO - Extraindo dados para: October de 2022\n",
      "17/02/2025 01:00:31 - INFO - Extraindo dados para: November de 2022\n",
      "17/02/2025 01:00:32 - INFO - Extraindo dados para: December de 2022\n",
      "17/02/2025 01:00:32 - INFO - Extraindo dados para: January de 2023\n",
      "17/02/2025 01:00:33 - INFO - Extraindo dados para: February de 2023\n",
      "17/02/2025 01:00:33 - INFO - Extraindo dados para: March de 2023\n",
      "17/02/2025 01:00:34 - INFO - Extraindo dados para: April de 2023\n",
      "17/02/2025 01:00:34 - INFO - Extraindo dados para: May de 2023\n",
      "17/02/2025 01:00:35 - INFO - Extraindo dados para: June de 2023\n",
      "17/02/2025 01:00:37 - INFO - Extraindo dados para: July de 2023\n",
      "17/02/2025 01:00:38 - INFO - Extraindo dados para: August de 2023\n",
      "17/02/2025 01:00:40 - INFO - Extraindo dados para: September de 2023\n",
      "17/02/2025 01:00:41 - INFO - Extraindo dados para: October de 2023\n",
      "17/02/2025 01:00:41 - INFO - Extraindo dados para: November de 2023\n",
      "17/02/2025 01:00:42 - INFO - Extraindo dados para: December de 2023\n",
      "17/02/2025 01:00:42 - INFO - Extraindo dados para: January de 2024\n",
      "17/02/2025 01:00:43 - INFO - Extraindo dados para: February de 2024\n",
      "17/02/2025 01:00:43 - INFO - Extraindo dados para: March de 2024\n",
      "17/02/2025 01:00:44 - INFO - Extraindo dados para: April de 2024\n",
      "17/02/2025 01:00:44 - INFO - Extraindo dados para: May de 2024\n",
      "17/02/2025 01:00:45 - INFO - Extraindo dados para: June de 2024\n",
      "17/02/2025 01:00:47 - INFO - Extraindo dados para: July de 2024\n",
      "17/02/2025 01:00:49 - INFO - Extraindo dados para: August de 2024\n",
      "17/02/2025 01:00:52 - INFO - Extraindo dados para: September de 2024\n",
      "17/02/2025 01:00:53 - INFO - Dados extraídos e salvos com sucesso no arquivo 'C:\\Users\\ana.brum\\Desktop\\DadosMeteorologicos\\dados_geada_automatico.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Diminuir o nível de log para o httpx e outros loggers de terceiros\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "ids_nao_mapeados = {\n",
    "    \"Santana Do Livramento\": 430016,\n",
    "    \"São Félix Do Araguaia\": 5107859,\n",
    "    \"São Luiz Do Paraitinga\": 3550001,\n",
    "    \"Mal. Cândido Rondon\": 4114609 , \n",
    "    \"Mal. Candido Rondon\":4114609\n",
    "}\n",
    "Estação = \"Automatica\"\n",
    "\n",
    "def limpar_nome_municipio(nome_municipio: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove partes do nome do município que não são relevantes para a busca do código IBGE.\n",
    "    \"\"\"\n",
    "    # Remove tudo após o hífen ou parêntese\n",
    "    nome_limpo = nome_municipio.split(\"- \")[0].split(\" (\")[0].strip()\n",
    "    return nome_limpo\n",
    "\n",
    "def fazer_requisicao(url: str, timeout: int = 10) -> list:\n",
    "    \"\"\"\n",
    "    Faz a requisição para a API e retorna os dados.\n",
    "    \n",
    "    Parâmetros:\n",
    "        url (str): URL da requisição.\n",
    "        timeout (int): Tempo máximo de espera para a resposta.\n",
    "\n",
    "    Retorna:\n",
    "        list: Dados da resposta em formato JSON ou uma lista vazia.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = httpx.get(url, timeout=timeout)\n",
    "        response.raise_for_status()  # Levanta exceção para códigos HTTP >= 400\n",
    "        dados = response.json()\n",
    "\n",
    "        for item in dados:\n",
    "            item[\"Estação\"] = \"Automatica\"  \n",
    "\n",
    "        return dados\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        logger.error(f\"Erro HTTP {e.response.status_code} ao fazer requisição para {url}\")\n",
    "        return []\n",
    "    except httpx.RequestError as e:\n",
    "        logger.error(f\"Erro na requisição: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def obter_codigo_ibge(nome_municipio: str) -> int:\n",
    "    # Limpa o nome do município\n",
    "    nome_municipio_limpo = limpar_nome_municipio(nome_municipio)\n",
    "   \n",
    "\n",
    "    # Verifica se o município está no dicionário de mapeamento manual\n",
    "    if nome_municipio_limpo in ids_nao_mapeados:\n",
    "        return ids_nao_mapeados[nome_municipio_limpo]  # Retorna o código diretamente do dicionário\n",
    "\n",
    "    # Se o município não estiver no dicionário, vamos tentar a API do IBGE\n",
    "    url = \"https://servicodados.ibge.gov.br/api/v1/localidades/municipios\"\n",
    "    municipios = fazer_requisicao(url)\n",
    "\n",
    "    if not municipios:  # Caso a API não retorne dados\n",
    "        logger.error(f\"Erro ao obter dados do IBGE. Informe manualmente o código para {nome_municipio_limpo}.\")\n",
    "        return solicitar_codigo_manual(nome_municipio_limpo)\n",
    "\n",
    "    # Se o município for encontrado na API\n",
    "    for municipio in municipios:\n",
    "        if municipio['nome'].lower() == nome_municipio_limpo.lower():\n",
    "            return municipio['id']\n",
    "\n",
    "    # Se o município não foi encontrado na API, solicita o código manualmente\n",
    "    logger.warning(f\"Código IBGE para {nome_municipio_limpo} não encontrado. Será necessário inserir manualmente.\")\n",
    "    return solicitar_codigo_manual(nome_municipio_limpo)\n",
    "\n",
    "def solicitar_codigo_manual(nome_municipio: str) -> int:\n",
    "    while True:\n",
    "        try:\n",
    "            codigo_manual = int(input(f\"Informe o código IBGE para {nome_municipio}: \"))\n",
    "            ids_nao_mapeados[nome_municipio] = codigo_manual  # Salva para futuras consultas\n",
    "            return codigo_manual\n",
    "        except ValueError:\n",
    "            print(\"Código inválido. Insira um número válido.\")\n",
    "\n",
    "def formatar_data_brasileira(data_iso: str) -> str:\n",
    "    \"\"\"\n",
    "    Converte a data do formato ISO para o formato brasileiro.\n",
    "\n",
    "    Parâmetros:\n",
    "        data_iso (str): Data em formato ISO (YYYY-MM-DD).\n",
    "\n",
    "    Retorna:\n",
    "        str: Data no formato DD/MM/YYYY.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data_formatada = datetime.strptime(data_iso, '%Y-%m-%d').strftime('%d/%m/%Y')\n",
    "        return data_formatada\n",
    "    except ValueError:\n",
    "        logger.error(f\"Erro ao formatar a data: {data_iso}\")\n",
    "        return \"Data inválida\"\n",
    "\n",
    "def formatar_temperatura(temperatura: str) -> float:\n",
    "    \"\"\"\n",
    "    Converte a temperatura para um número float.\n",
    "\n",
    "    Parâmetros:\n",
    "        temperatura (str): Valor da temperatura.\n",
    "\n",
    "    Retorna:\n",
    "        float: Temperatura formatada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return round(float(temperatura), 1)  # Garante que seja float com 1 casa decimal\n",
    "    except (TypeError, ValueError):\n",
    "        logger.error(f\"Erro ao formatar a temperatura: {temperatura}\")\n",
    "        return None  # Ou pode retornar float('nan') se preferir um valor numérico inválido\n",
    "\n",
    "def calcular_intensidade(temp_min: str) -> str:\n",
    "    \"\"\"\n",
    "    Calcula a intensidade da geada com base na temperatura mínima.\n",
    "\n",
    "    Parâmetros:\n",
    "        temp_min (str): Temperatura mínima.\n",
    "\n",
    "    Retorna:\n",
    "        str: Intensidade da geada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        temp_min_float = float(temp_min)\n",
    "        if temp_min_float < 1:\n",
    "            return \"Forte\"\n",
    "        elif temp_min_float <= 3:\n",
    "            return \"Moderada\"\n",
    "        else:\n",
    "            return \"Fraca\"\n",
    "    except (TypeError, ValueError):\n",
    "        return \"N/A\"\n",
    "\n",
    "def buscar_id_por_nome(cidades: list, nome_cidade: str) -> int:\n",
    "    \"\"\"\n",
    "    Busca o ID do município pelo nome.\n",
    "\n",
    "    Parâmetros:\n",
    "        cidades (list): Lista de dicionários com os dados dos municípios.\n",
    "        nome_cidade (str): Nome do município a ser buscado.\n",
    "\n",
    "    Retorna:\n",
    "        int: ID do município ou -1 se não for encontrado.\n",
    "    \"\"\"\n",
    "    nome_cidade_normalizado = unidecode.unidecode(nome_cidade).lower()\n",
    "    for cidade in cidades:\n",
    "        nome_cidade_api_normalizado = unidecode.unidecode(cidade[\"nome\"]).lower()\n",
    "        if nome_cidade_api_normalizado == nome_cidade_normalizado:\n",
    "            return cidade[\"id\"]\n",
    "    return -1\n",
    "\n",
    "def extrair_dados_geada(folder_path: str = r\"C:\\Users\\ana.brum\\Desktop\\DadosMeteorologicos\"):\n",
    "    \"\"\"\n",
    "    Extrai os dados de geadas da API e salva em um arquivo Excel.\n",
    "    \n",
    "    Parâmetros:\n",
    "        folder_path (str): Caminho da pasta onde o arquivo Excel será salvo.\n",
    "    \"\"\"\n",
    "    cidades = fazer_requisicao(\"https://servicodados.ibge.gov.br/api/v1/localidades/municipios\")\n",
    "    if not cidades:\n",
    "        logger.error(\"Não foi possível obter a lista de municípios.\")\n",
    "        return\n",
    "\n",
    "    data_inicio = datetime(2017, 1, 1)\n",
    "    data_fim = datetime(2024, 9, 30)\n",
    "    dados_tratados = []\n",
    "\n",
    "    while data_inicio <= data_fim:\n",
    "        ano = data_inicio.year\n",
    "        mes = data_inicio.month\n",
    "        nome_mes = data_inicio.strftime('%B').capitalize()\n",
    "\n",
    "        logger.info(f\"Extraindo dados para: {nome_mes} de {ano}\")\n",
    "\n",
    "        primeiro_dia = data_inicio.strftime(\"%Y-%m-%d\")\n",
    "        ultimo_dia = (data_inicio + timedelta(days=calendar.monthrange(ano, mes)[1] - 1)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        url = f\"https://apitempo.inmet.gov.br/geada/{primeiro_dia}/{ultimo_dia}/AUTOMATICA\"\n",
    "        dados = fazer_requisicao(url)\n",
    "\n",
    "        # Tratamento dos dados\n",
    "        if dados:\n",
    "            for item in dados:\n",
    "                uf = item.get(\"UF\", \"N/A\")\n",
    "                nome_cidade = item.get(\"NOME\", \"N/A\").title()\n",
    "                nome_cidade_limpo = limpar_nome_municipio(nome_cidade)  # Limpa o nome do município\n",
    "                data_ocorrencia = formatar_data_brasileira(item.get(\"DT_MEDICAO\"))\n",
    "                temp_min = item.get(\"TEMP_MIN\")\n",
    "                temperatura_formatada = formatar_temperatura(temp_min)\n",
    "                intensidade = calcular_intensidade(temp_min)\n",
    "                id_cidade = buscar_id_por_nome(cidades, nome_cidade_limpo)\n",
    "                item[\"Estação\"] = \"Automatica\"\n",
    "    \n",
    "\n",
    "                # Adicionando os dados tratados à lista\n",
    "                dados_tratados.append([id_cidade, uf, nome_cidade_limpo, data_ocorrencia, temperatura_formatada, intensidade,Estação])\n",
    "\n",
    "        # Avançar para o próximo mês\n",
    "        data_inicio += timedelta(days=calendar.monthrange(ano, mes)[1])\n",
    "\n",
    "    # Criar DataFrame com os dados tratados\n",
    "    colunas = [\"Cod. IBGE\", \"Uf\", \"Município\", \"Dia de ocorrência\", \"Temperatura Mínima\", \"Intensidade\", \"Estação\"]\n",
    "    df = pd.DataFrame(dados_tratados, columns=colunas)\n",
    "\n",
    "    # Certificando-se de que a pasta existe\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Caminho completo do arquivo Excel\n",
    "    excel_file = os.path.join(folder_path, \"dados_geada_automatico.xlsx\")\n",
    "    df.to_excel(excel_file, index=False)\n",
    "    logger.info(f\"Dados extraídos e salvos com sucesso no arquivo '{excel_file}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    extrair_dados_geada()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
